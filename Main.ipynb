{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "colab": {
      "name": "Main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "medieval-service"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from keras.optimizers import SGD\n",
        "from tensorflow.keras import datasets, layers, models, regularizers\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "medieval-service",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blocked-accessory"
      },
      "source": [
        "def preprocessDataset(dataset):\n",
        "    \"\"\"\n",
        "    Preprocesses an entire set of datapoints so that they are usable by a neural network\n",
        "\n",
        "    :param dataset: The dataset that is to be preprocessed in the form (images, labels)\n",
        "    :return: The preprocessed dataset in the form (processedImages, processedLabels)\n",
        "    \"\"\"\n",
        "\n",
        "    # Unpacks the dataset into the images (input data) and labels (expected output data)\n",
        "    images, labels = dataset\n",
        "\n",
        "    # Preprocesses the input data\n",
        "    newImages = images.reshape(images.shape[0], images.shape[1], images.shape[2], 3)\n",
        "    # Condenses the values of the images so that they fall within 0 and 1\n",
        "    newImages = newImages / 255.0\n",
        "\n",
        "    # Preprocesses the expected output data\n",
        "\n",
        "    # Collapses the n-dimensional array into a 1D array\n",
        "    # For example:\n",
        "    # [ [ 1, 2 ], [ 3, 4 ] ]\n",
        "    # [ 1, 2, 3, 4 ]\n",
        "    newLabels = labels.flatten()\n",
        "\n",
        "    # Converts the labels from a 1D array of numbers ranging from 1 - 10 to a 2D array of 0s\n",
        "    # in which each number in the 1D array has a respective array within the 2D array, and\n",
        "    # the value of said number is the index in the other array that is a 1\n",
        "    #\n",
        "    # For example:\n",
        "    # 1D array: [ 1, 2, 2, 4, 3 ]\n",
        "    # One Hotted 2D Array:\n",
        "    # [ [ 1, 0, 0, 0 ],   // 1\n",
        "    #   [ 0, 1, 0, 0 ],   // 2\n",
        "    #   [ 0, 1, 0, 0 ],   // 2\n",
        "    #   [ 0, 0, 0, 1 ],   // 4\n",
        "    #   [ 0, 0, 1, 0 ] ]  // 3\n",
        "    newLabels = tf.one_hot(newLabels.astype(np.int32), depth=10)\n",
        "\n",
        "    return newImages, newLabels\n",
        "\n",
        "\n",
        "def getRawDatasets():\n",
        "    \"\"\"\n",
        "    :return: The unprocessed datasets that the neural network is to be trained on and tested against\n",
        "    \"\"\"\n",
        "\n",
        "    # Using the CIFAR-10 dataset\n",
        "    return tf.keras.datasets.cifar10.load_data()"
      ],
      "id": "blocked-accessory",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "international-rough"
      },
      "source": [
        "def getTrainingConfigurations():\n",
        "    \"\"\"\n",
        "    Epochs: The amount of times the neural network trains against the entire training dataset\n",
        "    Batch Size: The amount of samples ran through before the gradient update is applied\n",
        "    Callbacks: The set of callbacks that will be applied during the training (e.g. saving)\n",
        "    Optimizer: The method that will be used in training the neural network\n",
        "    Loss Function: The loss function the neural network will use to judge its performance\n",
        "    Metrics: The metrics that will allow the user to understand the performance of the neural network\n",
        "\n",
        "    :param saveDir: The directory where the neural network is saved, indicated only if loading a neural network\n",
        "    :return: A tuple of the configurations described above, in order\n",
        "    \"\"\"\n",
        "\n",
        "    epochs = 300\n",
        "    batchSize = 32\n",
        "\n",
        "    # Gets the datetime now as to create unique folders\n",
        "    timeNow = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    # The folder the fitness logs will be saved to\n",
        "    logDir = \"logs/fit/\" + timeNow\n",
        "    # The directory the neural network will be saved to\n",
        "    saveDir = \"save_files/\" + timeNow\n",
        "\n",
        "    ## TODO: TensorBoard callback can be removed\n",
        "    callbacks = [tf.keras.callbacks.TensorBoard(log_dir=logDir, histogram_freq=1),\n",
        "                 tf.keras.callbacks.ModelCheckpoint(filepath=saveDir, verbose=1)]\n",
        "\n",
        "    # Using Stochastic Gradient Descent, which estimates the gradient of the entire dataset\n",
        "    # instead of calculating the gradient at the current data point\n",
        "    optimizer = tf.keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
        "\n",
        "    # Calculates the loss based on the difference in value of the expected and actual outputs, with\n",
        "    # respect to the other outputs\n",
        "    loss = \"categorical_crossentropy\"\n",
        "\n",
        "    # Accuracy is being used as a user-friendly way of displaying the effectiveness of the neural network\n",
        "    metrics = [\"accuracy\"]\n",
        "\n",
        "    return epochs, batchSize, callbacks, optimizer, loss, metrics"
      ],
      "id": "international-rough",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qqDyhKyOOYN"
      },
      "source": [
        "def createModel(train_images):\n",
        "  \"\"\"\n",
        "  Creates and returns the model of our CNN\n",
        "  Num_classes: The number of classes (categories) in the CIFAR-10 dataset\n",
        "  Model: The model of our CNN to be returned\n",
        "\n",
        "  #TODO: Make this more elegant??\n",
        "  :param: Set of training images, used to determine the input shape\n",
        "  :return: An object of type tf.keras.Model\n",
        "  \"\"\"\n",
        "  # 10 categories in the CIFAR-10 dataset\n",
        "  num_classes = 10\n",
        "\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, 3, padding='same', input_shape=train_images.shape[1:], activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(32, 3, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout(0.25))\n",
        "\n",
        "  model.add(layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(64, 3, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout(0.45)) # was 0.35\n",
        "\n",
        "  model.add(layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.Conv2D(128, 3, activation='relu'))\n",
        "  model.add(layers.BatchNormalization())\n",
        "  model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(layers.Dropout(0.5)) # was 0.45\n",
        "\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.L2(0.001))) # added new regularizer\n",
        "  model.add(layers.Dropout(0.5))\n",
        "  model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  return model"
      ],
      "id": "7qqDyhKyOOYN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrB3zCk7PZpI"
      },
      "source": [
        "def getOptimizer():\n",
        "  \"\"\"\n",
        "  Opt: The optimizer to be returned, here it is a Stochastic Gradient Descent function with a learning rate of 0.001 and a momentum of 0.9\n",
        "\n",
        "  :return: Our optimization function\n",
        "  \"\"\"\n",
        "  opt = SGD(lr=0.001, momentum=0.9)\n",
        "  return opt"
      ],
      "id": "HrB3zCk7PZpI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "amazing-blogger",
        "outputId": "b6649546-f2a5-43c9-b35f-6b4addf4ecfb"
      },
      "source": [
        "# Main function\n",
        "if __name__ == \"__main__\":\n",
        "    # Training configurations\n",
        "    epochs, batchSize, callbacks, optimizer, loss, metrics = getTrainingConfigurations()\n",
        "\n",
        "    # Raw datasets\n",
        "    rawTrainingDataset, rawTestingDataset = getRawDatasets()\n",
        "\n",
        "    # Preprocessed datasets\n",
        "    trainingImages, trainingLabels = preprocessDataset(rawTrainingDataset)\n",
        "    testingImages, testingLabels = preprocessDataset(rawTestingDataset)\n",
        "\n",
        "    # Model\n",
        "    model = createModel(trainingImages)\n",
        "\n",
        "    # Optimizer\n",
        "    opt = getOptimizer()\n",
        "\n",
        "    # Compile model, uses cross entropy as a loss function\n",
        "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Begin training the model\n",
        "    history = model.fit(trainingImages, trainingLabels, epochs=epochs, validation_data=(testingImages, testingLabels), batch_size=batchSize, callbacks=callbacks)\n",
        "\n",
        "    # Create plot\n",
        "    plt.plot(history.history['accuracy'], label='accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.ylim([0.5, 1])\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    test_loss, test_acc = model.evaluate(testingImages, testingLabels, verbose=2)"
      ],
      "id": "amazing-blogger",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_24 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "conv2d_25 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 30, 30, 32)        128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_26 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 15, 15, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 13, 13, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 6, 6, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 6, 6, 128)         512       \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 4, 4, 128)         147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 4, 4, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 556,586\n",
            "Trainable params: 555,690\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n",
            "1563/1563 [==============================] - 33s 20ms/step - loss: 2.9450 - accuracy: 0.2487 - val_loss: 2.0397 - val_accuracy: 0.4430\n",
            "\n",
            "Epoch 00001: saving model to save_files/20210507-193023\n",
            "INFO:tensorflow:Assets written to: save_files/20210507-193023/assets\n",
            "313/313 - 2s - loss: 2.0397 - accuracy: 0.4430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}